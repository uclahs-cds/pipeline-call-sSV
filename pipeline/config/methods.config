import nextflow.util.SysHelper

manifest {
    mainScript = "call-sSV.nf"
    nextflowVersion = ">=20.07.1"
    author = "Yu Pan, Ghouse Mohammed"
    homePage = "https://github.com/uclahs-cds/pipeline-call-sSV"
    description = "A pipeline to call Somatic SV utilizing Delly"
    version = "1.0.0"
    }

params {
    // resource configuraton for entire pipeline
    max_number_of_parallel_jobs = 1
}

methods {
    check_permissions = { path ->
        def filePath = new File(path)

        if (filePath.exists()) {
            if (filePath.canWrite()) {
                return
                }
            throw new Exception("${path} is not writable")
            }

        // Attempts to create directory if the path does not exist
        if (!filePath.mkdirs()) {
            throw new Exception("${path} does not exist and could not create")
            }
        }

    set_output_dir = {
        def date = new Date().format('yyyyMMdd-HHmmss')

        if (params.blcds_registered_dataset) {
            if ("${params.dataset_id.length()}" != 11) {
                throw new Exception("Dataset id must be eleven characters long")
                }
            def disease = "${params.dataset_id.substring(0,4)}"
            params.output_log_dir = "${params.avere_prefix}/$disease/${params.dataset_id}/${patient}/${sample}/DNA/WGS/aligned/${params.reference_prefix}/log/call-gSV/$date"
            params.disease = "${disease}"
            } 
        else {
            //params.output_log_dir = "${params.output_dir}/$date/log/"
            params.output_dir = "${params.output_dir}/call-sSV-${date}"
            params.output_log_dir = "${params.output_dir}/log"
            }

        params.date = "${date}"
        }

    // Process specific scope
    set_process = {
        // monitor process jobs with local (not slurm) executor
        process.executor = "local"
        // total amount of resources avaible to the pipeline
        process.maxForks = params.max_number_of_parallel_jobs
        // echo stdout of each step to stdout of pipeline
        process.echo = true
        process.cache = params.cache_intermediate_pipeline_steps
        }

    // Location of Nextflow temp directories
    set_env = {
        workDir = params.temp_dir
        }

    // Pipeline monitoring and metric files
    set_timeline = {
        timeline.enabled = true
        timeline.file = "${params.output_log_dir}/timeline.html"
    }

    set_trace = {
        trace.enabled = true
        trace.file = "${params.output_log_dir}/trace.txt"
        }

    set_report = {
        report.enabled = true
        report.file = "${params.output_log_dir}/report.html"
        }

    set_node_config = {
        def node_cpus = SysHelper.getAvailCpus()
        def node_mem  = SysHelper.getAvailMemory().toString()

        if (node_cpus == 2) {
            includeConfig "${projectDir}/config/F2.config"
            } 
        else if (node_cpus == 72 ) {
            includeConfig "${projectDir}/config/F72.config"
            } 
        else if (node_cpus == 64 ) {
            includeConfig "${projectDir}/config/M64.config"
            } 
        else {
            throw new Exception('ERROR: System resources not as expected, unable to assign resources.')
            }
        }

    // Set up env, timeline, trace, and report above.
    setup = {
        methods.set_output_dir()
        methods.check_permissions(params.output_log_dir)
        
        methods.set_env()
        methods.set_process()
        methods.set_timeline()
        methods.set_trace()
        methods.set_report()
        methods.set_node_config()
        }
    }


methods.setup()

// Enable docker
docker {
    enabled = true
    sudo = (params.sge_scheduler) ? true : false // Set to true if run on SGE

    // Pass user's UID/GID and group IDs to Docker
    uid_and_gid = "-u \$(id -u):\$(id -g)"
    all_group_ids = "\$(for i in `id --real --groups`; do echo -n \"--group-add=\$i \"; done)"

    runOptions = "${uid_and_gid} ${all_group_ids}"
    }
